<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>Assessing Model Fairness Across Binary Protected Attributes</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Assessing Model Fairness Across Binary
Protected Attributes</h1>



<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>This vingette demonstrates how to obtain, report and interpret model
fairness metrics for binary protected attributes with the
<code>fairmetrics</code> package. We illustrate this through a case
study based on a preprocessed version of the MIMIC-II clinical database
[1], which has been previously studied to explore the relationship
between indwelling arterial catheters in hemodynamically stable patients
and respiratory failure in relation to mortality outcomes [2]. The
original, unprocessed dataset is publicly available through <a href="https://physionet.org/content/mimic2-iaccd/1.0/">PhysioNet</a>
[3]. A preprocessed version of this dataset is included in the
<code>fairmetrics</code> package as the <code>mimic_preprocessed</code>
and is used in this vingette.</p>
</div>
<div id="data-split-and-model-construction" class="section level1">
<h1>Data Split and Model Construction</h1>
<p>In this setting, we construct a model that will predict 28-day
mortality (<code>day_28_flg</code>). To do this, we split the dataset
into a training and testing sets and fit a random forest model. The
first 700 patients are used as the training set and the remaining
patients are used as the testing set. After the model is fit, it is used
to predict 28-day mortality. The predicted probabilities are saved as
new column in the testing data and are used to assess model
fairness.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="co"># Load required libraries</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="fu">library</span>(fairmetrics)</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="fu">library</span>(randomForest)</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="co"># Use 700 labels to train on the mimic_preprocessed dataset</span></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> mimic_preprocessed <span class="sc">%&gt;%</span></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">row_number</span>() <span class="sc">&lt;=</span> <span class="dv">700</span>)</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="co"># Test the model on the remaining data</span></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> mimic_preprocessed <span class="sc">%&gt;%</span></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">row_number</span>() <span class="sc">&gt;</span> <span class="dv">700</span>)</span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a><span class="co"># Fit a random forest model</span></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a>rf_model <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(<span class="fu">factor</span>(day_28_flg) <span class="sc">~</span> ., <span class="at">data =</span> train_data, <span class="at">ntree =</span> <span class="dv">1000</span>)</span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a><span class="co"># Save model prediction</span></span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a>test_data<span class="sc">$</span>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_model, <span class="at">newdata =</span> test_data, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>)[, <span class="dv">2</span>]</span></code></pre></div>
</div>
<div id="fairness-evaluation" class="section level1">
<h1>Fairness Evaluation</h1>
<p>The <code>fairmetrics</code> package is used to assess model fairness
across binary protected attributes. This means that the number of unique
values in the protected attribute column need to be exactly two. To
evaluate fairness of the random forest model which we fit, we examine
patient gender as the binary protected attribute.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="co"># Recode gender variable explicitly for readability: </span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> test_data <span class="sc">%&gt;%</span></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">gender =</span> <span class="fu">ifelse</span>(gender_num <span class="sc">==</span> <span class="dv">1</span>, <span class="st">&quot;Male&quot;</span>, <span class="st">&quot;Female&quot;</span>))</span></code></pre></div>
<p>Since many fairness metrics require binary predictions, we threshold
the predicted probabilities using a fixed cutoff. We set a threshold of
0.41 to maintain the overall false positive rate (FPR) at approximately
5%. To evaluate specific fairness metrics, its possible to do so with
the <code>eval_*</code> functions (for a list of the functions contained
in <code>fairmetrics</code> see <a href="https://jianhuig.github.io/fairmetrics/reference/index.html">here</a>).
For example, if we are interested in calculating the statistical parity
of our model across gender (here assumed to be binary), we write:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="fu">eval_stats_parity</span>(</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>  <span class="at">data =</span> test_data, </span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>  <span class="at">outcome =</span> <span class="st">&quot;day_28_flg&quot;</span>,</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>  <span class="at">group =</span> <span class="st">&quot;gender&quot;</span>,</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>  <span class="at">probs =</span> <span class="st">&quot;pred&quot;</span>,</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>  <span class="at">cutoff =</span> <span class="fl">0.41</span>,</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>  <span class="at">message =</span> <span class="cn">TRUE</span></span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>)</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a><span class="co">#&gt; There is evidence that model does not satisfy statistical parity.</span></span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a><span class="co">#&gt;                     Metric GroupFemale GroupMale Difference  95% Diff CI Ratio</span></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a><span class="co">#&gt; 1 Positive Prediction Rate        0.17      0.09       0.08 [0.04, 0.12]  1.89</span></span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a><span class="co">#&gt;   95% Ratio CI</span></span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a><span class="co">#&gt; 1 [1.35, 2.64]</span></span></code></pre></div>
<p>The dataframe returned gives the positive prediction rate between the
groups defined by the binary protected attribute
(<code>GroupFemale</code> and <code>GroupMale</code> in this case), the
difference and ratios between the groups and the bootstrap calculated
confidence intervals for the estimated difference and ratios. For
inference, it can be considered that confidence interval which contains
0 in its range for difference or 1 for ratio as insignificant.</p>
<p>The above syntax can be extended to the other <code>eval_*</code>
functions as well. Additionally, if one wishes to calculate various
fairness metrics (and their confidence intervals) for the model
simultaneously, we pass our test data with its predicted results into
the <code>get_fairness_metrics</code> function.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="fu">get_fairness_metrics</span>(</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>  <span class="at">data =</span> test_data,</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>  <span class="at">outcome =</span> <span class="st">&quot;day_28_flg&quot;</span>,</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>  <span class="at">group =</span> <span class="st">&quot;gender&quot;</span>,</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>  <span class="at">probs =</span> <span class="st">&quot;pred&quot;</span>,</span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a>  <span class="at">cutoff =</span> <span class="fl">0.41</span></span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a> )</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a><span class="co">#&gt;            Fairness Assesment                                  Metric</span></span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a><span class="co">#&gt; 1          Statistical Parity                Positive Prediction Rate</span></span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a><span class="co">#&gt; 2           Equal Opportunity                     False Negative Rate</span></span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a><span class="co">#&gt; 3         Predictive Equality                     False Positive Rate</span></span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a><span class="co">#&gt; 4  Balance for Positive Class           Avg. Predicted Positive Prob.</span></span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a><span class="co">#&gt; 5  Balance for Negative Class           Avg. Predicted Negative Prob.</span></span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a><span class="co">#&gt; 6  Positive Predictive Parity               Positive Predictive Value</span></span>
<span id="cb4-15"><a href="#cb4-15" tabindex="-1"></a><span class="co">#&gt; 7  Negative Predictive Parity               Negative Predictive Value</span></span>
<span id="cb4-16"><a href="#cb4-16" tabindex="-1"></a><span class="co">#&gt; 8          Brier Score Parity                             Brier Score</span></span>
<span id="cb4-17"><a href="#cb4-17" tabindex="-1"></a><span class="co">#&gt; 9     Overall Accuracy Parity                                Accuracy</span></span>
<span id="cb4-18"><a href="#cb4-18" tabindex="-1"></a><span class="co">#&gt; 10         Treatment Equality (False Negative)/(False Positive) Ratio</span></span>
<span id="cb4-19"><a href="#cb4-19" tabindex="-1"></a><span class="co">#&gt;    GroupFemale GroupMale Difference    95% Diff CI Ratio 95% Ratio CI</span></span>
<span id="cb4-20"><a href="#cb4-20" tabindex="-1"></a><span class="co">#&gt; 1         0.17      0.09       0.08   [0.04, 0.12]  1.89 [1.35, 2.64]</span></span>
<span id="cb4-21"><a href="#cb4-21" tabindex="-1"></a><span class="co">#&gt; 2         0.38      0.57      -0.19 [-0.34, -0.04]  0.67 [0.47, 0.94]</span></span>
<span id="cb4-22"><a href="#cb4-22" tabindex="-1"></a><span class="co">#&gt; 3         0.08      0.03       0.05   [0.02, 0.08]  2.67  [1.4, 5.08]</span></span>
<span id="cb4-23"><a href="#cb4-23" tabindex="-1"></a><span class="co">#&gt; 4         0.46      0.37       0.09   [0.04, 0.14]  1.24 [1.09, 1.42]</span></span>
<span id="cb4-24"><a href="#cb4-24" tabindex="-1"></a><span class="co">#&gt; 5         0.15      0.11       0.04   [0.02, 0.06]  1.36 [1.17, 1.59]</span></span>
<span id="cb4-25"><a href="#cb4-25" tabindex="-1"></a><span class="co">#&gt; 6         0.62      0.68      -0.06  [-0.23, 0.11]  0.91 [0.71, 1.18]</span></span>
<span id="cb4-26"><a href="#cb4-26" tabindex="-1"></a><span class="co">#&gt; 7         0.92      0.91       0.01  [-0.03, 0.05]  1.01 [0.97, 1.05]</span></span>
<span id="cb4-27"><a href="#cb4-27" tabindex="-1"></a><span class="co">#&gt; 8         0.09      0.08       0.01  [-0.01, 0.03]  1.12 [0.88, 1.43]</span></span>
<span id="cb4-28"><a href="#cb4-28" tabindex="-1"></a><span class="co">#&gt; 9         0.87      0.89      -0.02  [-0.06, 0.02]  0.98 [0.93, 1.02]</span></span>
<span id="cb4-29"><a href="#cb4-29" tabindex="-1"></a><span class="co">#&gt; 10        1.03      2.78      -1.75    [-3.6, 0.1]  0.37 [0.17, 0.79]</span></span></code></pre></div>
<p>With the <code>get_fairness_metrics</code> function, it’s possible to
examine the bootstrapped confidence intervals to determine which
fairness criterion show evidence of violation. From the above output,
Statistical Parity, Equal Opportunity, Predictive Equality, Balance for
Positive Class and Balance for Negative Class show evidence of being
violated, while Positive Predictive Parity, Negative Predictive Parity,
Brier Score Parity and Overall Accuracy Parity do not. Treatment
Equality remains ambiguous: when assessed by difference, the 95%
bootstrapped confidence interval crosses 0 - indicating that there is no
evidence indicating that the fairness criterion is violated, but when
assessed by ratio, the interval crosses 1 - which indicates that there
is.</p>
<blockquote>
<p><strong>NOTE:</strong></p>
<p>Statistical inference from bootstrapped confidence intervals should
be interpreted with caution. A confidence interval crossing 0 (for
differences) or 1 (for ratios) means the evidence is inconclusive rather
than proving absence of unfairness. Apparent violations may reflect
sampling variability rather than systematic bias. Always complement
these results with domain knowledge, sensitivity analyses, and
additional fairness diagnostics before drawing strong conclusions about
a specific fairness assessment.</p>
</blockquote>
<p>While <code>fairmetrics</code> focuses only on assessing fairness of
models across binary protected attributes, it is possible to work with
protected attributes which consist of more than two groups by using
“one-vs-all” comparisons and a little bit of data wrangling to create
the appropriate columns.</p>
</div>
<div id="conditional-fairness-evaluation" class="section level1">
<h1>Conditional Fairness Evaluation</h1>
<p>To evaluate a model’s fairness for a specific subgroup, simply subset
the data. For example, to evaluate the conditional statistical parity
among subjects aged 60 and older using the previously fitted random
forest model, subsetting the test data and and passing it through the
<code>eval_stats_parity</code> is all that’s required.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="fu">eval_stats_parity</span>(</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>  <span class="at">data =</span> <span class="fu">subset</span>(test_data, age <span class="sc">&gt;=</span> <span class="dv">60</span>), </span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>  <span class="at">outcome =</span> <span class="st">&quot;day_28_flg&quot;</span>,</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>  <span class="at">group =</span> <span class="st">&quot;gender&quot;</span>,</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>  <span class="at">probs =</span> <span class="st">&quot;pred&quot;</span>,</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>  <span class="at">cutoff =</span> <span class="fl">0.41</span>,</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>  <span class="at">message =</span> <span class="cn">TRUE</span></span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a>)</span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a><span class="co">#&gt; There is not enough evidence that the model does not satisfy</span></span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a><span class="co">#&gt;             statistical parity.</span></span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a><span class="co">#&gt;                     Metric GroupFemale GroupMale Difference 95% Diff CI Ratio</span></span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a><span class="co">#&gt; 1 Positive Prediction Rate        0.34      0.25       0.09   [0, 0.18]  1.36</span></span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a><span class="co">#&gt;   95% Ratio CI</span></span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a><span class="co">#&gt; 1 [1.01, 1.84]</span></span></code></pre></div>
<p>From the bootstrapped confidence intervals for the difference and the
ratio, we note that there is evidence that statistical parity is
violated based on the difference and ratio confidence intervals between
the male and female subjects aged 60 and over. A similar example can be
constructed with <code>get_fairness_metrics</code> for a more
comprehensive view of the conditional fairness of the model.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="fu">get_fairness_metrics</span>(</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>  <span class="at">data =</span> <span class="fu">subset</span>(test_data, age <span class="sc">&gt;=</span> <span class="dv">60</span>), </span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>  <span class="at">outcome =</span> <span class="st">&quot;day_28_flg&quot;</span>,</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>  <span class="at">group =</span> <span class="st">&quot;gender&quot;</span>,</span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a>  <span class="at">probs =</span> <span class="st">&quot;pred&quot;</span>,</span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>  <span class="at">cutoff =</span> <span class="fl">0.41</span></span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a>)</span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a><span class="co">#&gt;            Fairness Assesment                                  Metric</span></span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a><span class="co">#&gt; 1          Statistical Parity                Positive Prediction Rate</span></span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a><span class="co">#&gt; 2           Equal Opportunity                     False Negative Rate</span></span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a><span class="co">#&gt; 3         Predictive Equality                     False Positive Rate</span></span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a><span class="co">#&gt; 4  Balance for Positive Class           Avg. Predicted Positive Prob.</span></span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a><span class="co">#&gt; 5  Balance for Negative Class           Avg. Predicted Negative Prob.</span></span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a><span class="co">#&gt; 6  Positive Predictive Parity               Positive Predictive Value</span></span>
<span id="cb6-15"><a href="#cb6-15" tabindex="-1"></a><span class="co">#&gt; 7  Negative Predictive Parity               Negative Predictive Value</span></span>
<span id="cb6-16"><a href="#cb6-16" tabindex="-1"></a><span class="co">#&gt; 8          Brier Score Parity                             Brier Score</span></span>
<span id="cb6-17"><a href="#cb6-17" tabindex="-1"></a><span class="co">#&gt; 9     Overall Accuracy Parity                                Accuracy</span></span>
<span id="cb6-18"><a href="#cb6-18" tabindex="-1"></a><span class="co">#&gt; 10         Treatment Equality (False Negative)/(False Positive) Ratio</span></span>
<span id="cb6-19"><a href="#cb6-19" tabindex="-1"></a><span class="co">#&gt;    GroupFemale GroupMale Difference   95% Diff CI Ratio 95% Ratio CI</span></span>
<span id="cb6-20"><a href="#cb6-20" tabindex="-1"></a><span class="co">#&gt; 1         0.34      0.25       0.09  [0.01, 0.17]  1.36 [1.01, 1.83]</span></span>
<span id="cb6-21"><a href="#cb6-21" tabindex="-1"></a><span class="co">#&gt; 2         0.30      0.46      -0.16    [-0.32, 0]  0.65 [0.41, 1.04]</span></span>
<span id="cb6-22"><a href="#cb6-22" tabindex="-1"></a><span class="co">#&gt; 3         0.18      0.11       0.07 [-0.01, 0.15]  1.64 [0.91, 2.96]</span></span>
<span id="cb6-23"><a href="#cb6-23" tabindex="-1"></a><span class="co">#&gt; 4         0.50      0.41       0.09  [0.04, 0.14]  1.22 [1.08, 1.38]</span></span>
<span id="cb6-24"><a href="#cb6-24" tabindex="-1"></a><span class="co">#&gt; 5         0.26      0.22       0.04  [0.01, 0.07]  1.18 [1.03, 1.36]</span></span>
<span id="cb6-25"><a href="#cb6-25" tabindex="-1"></a><span class="co">#&gt; 6         0.63      0.69      -0.06  [-0.22, 0.1]  0.91 [0.71, 1.17]</span></span>
<span id="cb6-26"><a href="#cb6-26" tabindex="-1"></a><span class="co">#&gt; 7         0.86      0.81       0.05 [-0.03, 0.13]  1.06 [0.96, 1.17]</span></span>
<span id="cb6-27"><a href="#cb6-27" tabindex="-1"></a><span class="co">#&gt; 8         0.14      0.16      -0.02 [-0.05, 0.01]  0.88 [0.71, 1.07]</span></span>
<span id="cb6-28"><a href="#cb6-28" tabindex="-1"></a><span class="co">#&gt; 9         0.78      0.78       0.00 [-0.08, 0.08]  1.00  [0.91, 1.1]</span></span>
<span id="cb6-29"><a href="#cb6-29" tabindex="-1"></a><span class="co">#&gt; 10        0.71      1.88      -1.17  [-2.54, 0.2]  0.38 [0.16, 0.89]</span></span></code></pre></div>
<p>Conditioning on subjects aged 60 and older, Statistical Parity,
Balance for Positive Class and Balance for Negative Class posses
evidence for being violated based on 95% bootstrapped confidence
intervals. While Predictive Equality, Positive Predictive Parity,
Negative Predictive Parity, Brier Score Parity and Overall Accuracy
Parity do not. Similar to the unconditioned case, Treatment Equality
remains ambiguous based on the contrast between the difference and ratio
confidence intervals. If difference is considered, there is evidence of
Treatment equality being violated. If ratio is considered, there does
not.</p>
</div>
<div id="appendix-confidence-interval-construction" class="section level1">
<h1>Appendix: Confidence Interval Construction</h1>
<p>The function <code>get_fairness_metrics()</code> computes Wald-type
confidence intervals for both group-specific and disparity metrics using
nonparametric bootstrap. To illustrate the construction of confidence
intervals (CIs), we use the following example involving the false
positive rate (<span class="math inline">\(FPR\)</span>).</p>
<p>Let <span class="math inline">\(\widehat{\textrm{FPR}}_a\)</span> and
<span class="math inline">\(\textrm{FPR}_a\)</span> denote the estimated
and true FPR in group <span class="math inline">\(A = a\)</span>. Then
the difference <span class="math inline">\(\widehat{\Delta}_{\textrm{FPR}} =
\widehat{\textrm{FPR}}_{a_1} - \widehat{\textrm{FPR}}_{a_0}\)</span>
satisfies (e.g., <a href="https://doi.org/10.1093/jrsssb/qkad107">Gronsbell et al.,
2018</a>):</p>
<p><span class="math display">\[
\sqrt{n}(\widehat{\Delta}_{\textrm{FPR}} - \Delta_{\textrm{FPR}})
\overset{d}{\to} \mathcal{N}(0, \sigma^2)
\]</span></p>
<p>We estimate the standard error of <span class="math inline">\(\widehat{\Delta}_{\textrm{FPR}}\)</span> using
bootstrap resampling within groups, and form a Wald-style confidence
interval:</p>
<p><span class="math display">\[
\widehat{\Delta}_{\textrm{FPR}} \pm z_{1-\alpha/2} \cdot
\widehat{\textrm{se}}(\widehat{\Delta}_{\textrm{FPR}})
\]</span></p>
<p>For <strong>ratios</strong>, such as <span class="math inline">\(\widehat{\rho}_{\textrm{FPR}} =
\widehat{\textrm{FPR}}_{a_1} / \widehat{\textrm{FPR}}_{a_0}\)</span>, we
apply a log transformation and use the delta method:</p>
<p><span class="math display">\[
\log(\widehat{\rho}_{\textrm{FPR}}) \pm z_{1-\alpha/2} \cdot
\widehat{\textrm{se}}\left[\log(\widehat{\rho}_{\textrm{FPR}})\right]
\]</span></p>
<p>Exponentiation of the bounds yields a confidence interval for the
ratio on the original scale:</p>
<p><span class="math display">\[
\left[
\exp\left\{\log(\widehat{\rho}_{\textrm{FPR}}) - z_{1-\alpha/2} \cdot
\widehat{\textrm{se}}\left[\log(\widehat{\rho}_{\textrm{FPR}})\right]\right\},\
\exp\left\{\log(\widehat{\rho}_{\textrm{FPR}}) + z_{1-\alpha/2} \cdot
\widehat{\textrm{se}}\left[\log(\widehat{\rho}_{\textrm{FPR}})\right]\right\}
\right].
\]</span></p>
</div>
<div id="references" class="section level1">
<h1>References</h1>
<ol style="list-style-type: decimal">
<li><p>Raffa, J. (2016). Clinical data from the MIMIC-II database for a
case study on indwelling arterial catheters (version 1.0). PhysioNet. <a href="https://doi.org/10.13026/C2NC7F" class="uri">https://doi.org/10.13026/C2NC7F</a>.</p></li>
<li><p>Raffa J.D., Ghassemi M., Naumann T., Feng M., Hsu D. (2016) Data
Analysis. In: Secondary Analysis of Electronic Health Records. Springer,
Cham</p></li>
<li><p>Goldberger, A., Amaral, L., Glass, L., Hausdorff, J., Ivanov, P.
C., Mark, R., … &amp; Stanley, H. E. (2000). PhysioBank, PhysioToolkit,
and PhysioNet: Components of a new research resource for complex
physiologic signals. Circulation [Online]. 101 (23),
pp. e215–e220.</p></li>
<li><p>Gao, J. et al. What is Fair? Defining Fairness in Machine
Learning for Health. arXiv.org <a href="https://arxiv.org/abs/2406.09307" class="uri">https://arxiv.org/abs/2406.09307</a> (2024).</p></li>
<li><p>Gronsbell, J. L. &amp; Cai, T. Semi-Supervised approaches to
efficient evaluation of model prediction performance. Journal of the
Royal Statistical Society Series B (Statistical Methodology) 80, 579–594
(2017).</p></li>
<li><p>Hort, M., Chen, Z., Zhang, J. M., Harman, M. &amp; Sarro, F. Bias
Mitigation for Machine Learning Classifiers: A Comprehensive survey.
arXiv.org <a href="https://arxiv.org/abs/2207.07068" class="uri">https://arxiv.org/abs/2207.07068</a> (2022).</p></li>
<li><p>Hsu, D. J. et al. The association between indwelling arterial
catheters and mortality in hemodynamically stable patients with
respiratory failure. CHEST Journal 148, 1470–1476 (2015).</p></li>
<li><p>Efron, B. &amp; Tibshirani, R. Bootstrap methods for standard
errors, confidence intervals, and other measures of statistical
accuracy. Statistical Science 1, (1986).</p></li>
</ol>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
